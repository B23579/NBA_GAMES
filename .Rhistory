install.packages("tidyverse")
library(tidyverse)
iris
summary(iris)
plot(iris)
plot(iris$Sepal.Length)
data = iris
summary(data)
plot(data)
plot(data$Sepal.Width~data&Sepal.Lenght)
dat = iris
summary(dat)
plot(data)
dataSetosa = data.class(dat$Species)
dr =  dat$Species
summary(dr)
plot(dr$setosa)
plot(dr$setosa)
dr = iris %>% group_by( Species) %>% summarise(Avg.Sepal.Ratio = mean(Sepal.Length/Sepal.Length), Avg.Sepal.Ratio = mean(Petal.Length/
Petal.Width ))
dr %>% gather(ratio, value,-Species)
plot(Petal.Length, Species)
dat$Species<- factor(dat$Species)
summary(dat)
str(dat)
dat.Setosa <- subset(dat, Species= "setosa")
plot(dat.Setosa)
plot(dat.Setosa)
boxplot(dat.Setosa)
plot(dat.Setosa)
str(dat.Setosa)
dat.Setosa<-droplevels(dat.Setosa)
str(dat.Setosa)
boxplot(dat.Setosa)
plot(dat.Setosa)
boxplot(dat.Setosa)
dat.versicolor <-droplevels(dat.vesicolor)
# species versicolor
dat.vesicolor <- subset(dat, Species="versicolor")
dat.versicolor <-droplevels(dat.vesicolor)
# species versicolor
dat.vesicolor <- subset(dat, Species="versicolor")
dat.vesicolor <-droplevels(dat.vesicolor)
str(dat.vesicolor)
dat.Setosa$Species <- subset(dat, Species= "setosa")
dat.Setosa$Species <- subset(dat, Species= "setosa")
dat.Setosa$Species<-droplevels(dat.Setosa$Species)
str(dat.Setosa)
boxplot(dat.Setosa)
levels(dat.Setosa)
dat = iris
dat <- iris
summary(dat)
plot(data)
dr = iris %>% group_by( Species) %>% summarise(Avg.Sepal.Ratio = mean(Sepal.Length/Sepal.Length), Avg.Sepal.Ratio = mean(Petal.Length/
Petal.Width ))
dr %>% gather(ratio, value,-Species)
dat$Species<- factor(dat$Species)
str(dat)
dat.Setosa$Species <- subset(dat, Species= "setosa")
dat.Setosa$Species<-droplevels(dat.Setosa$Species)
levels(dat.Setosa)
levels(dat.Setosa$Species)
dat$Species<- factor(dat$Species)
levels(dat$Species)
dat.Setosa$Species <- subset(dat, Species= "setosa")
levels(dat.Setosa$Species)
dat.Setosa$Species<-droplevels(dat.Setosa$Species)
levels(dat.Setosa$Species)
boxplot(dat.Setosa)
boxplot(Sepal.Lenght,dat.Setosa)
plot(Sepal.Lenght~Species,dat)
boxplot(Sepal.Lenght~Species,dat)
boxplot(dat$Sepal.Lenght~Species,dat)
boxplot(dat)
dat <- iris
summary(dat)
plot(data)
dat$Species<- factor(dat$Species)
levels(dat$Species)
boxplot(Sepal.Length~Species,dat)
boxplot(Sepal.With~Species,dat)
# petal
boxplot(Petal.Length~Species,dat)
boxplot(Petal.With~Species,dat)
boxplot(Petal.With~Species,dat, horizontal = True)
# 1 import iris data set
dat <- iris
# 2  summaries iris dataset
summary(dat)
# 3 plot iris dataset
plot(data)
dat$Species<- factor(dat$Species)
levels(dat$Species)
# sepal
boxplot(Sepal.Length~Species,dat)
# sepal
boxplot(Sepal.Length~Species,dat)
boxplot(Sepal.With~Species,dat)
# petal
boxplot(Petal.Length~Species,dat)
boxplot(Petal.With~Species,dat, horizontal = True)
dat.Setosa = subset(dat, Species=="setosa")
summary(dat.Setosa)
dat.Setosa <- subset(dat, Species=="setosa")
dat.Setosa$Species <-droplevels(dat.Setosa$Species)
summary(dat.Setosa)
plot(dat.Setosa)
plot(dat.Setosa$Sepal.Length,dat.Setosa$Sepal.Width)
plot(dat.Setosa$Sepal.Length,dat.Setosa$Petal.Length)
plot(dat.Setosa$Sepal.Length,dat.Setosa$Petal.Width)
plot(dat.Setosa)
plot(dat.Setosa$Petal.Length,dat.Setosa$Petal.Width)
dat.ver <- subset(dat, Species=="versicolora")
dat.ver$Species <-droplevels(dat.ver$Species)
summary(dat.ver)
plot(dat.ver)
dat.ver <- subset(dat, Species=="versicolor")
dat.ver$Species <-droplevels(dat.ver$Species)
summary(dat.ver)
plot(dat.ver)
plot(dat.ver$Sepal.Length,dat.ver$Sepal.Width)
plot(dat.ver$Sepal.Length,dat.ver$Petal.Length)
plot(dat.ver$Sepal.Length,dat.ver$Petal.Width)
plot(dat.ver$Petal.Length,dat.ver$Petal.Width)
dr = iris %>% group_by( Species) %>% summarise(Avg.Sepal.Ratio = mean(Sepal.Length/Sepal.Length), Avg.Sepal.Ratio = mean(Petal.Length/
Petal.Width ))
library(tidyverse)
geom_point(mapping = aes(x=iris$Sepal.Length,y=iris$Sepal.Width,color=Species)
ggplot(data=iris)+
geom_point(mapping = aes(x=iris$Sepal.Length,y=iris$Sepal.Width,color=Species))
ggplot(data=iris)+
geom_point(mapping = aes(x=iris$Sepal.Length,y=iris$Sepal.Width,color=iris$Species))
ggplot(data=iris)+
geom_point(mapping = aes(x=Sepal.Length,y=Sepal.Width,color=Species))
install.packages("tidyverse")
library(tidyverse)
install.packages("rpart")
library(rpart)
library(mrl)
install.packages("mlr")
library(mrl)
library(mlr)
library(mlr3)
install.packages("mlr3")
setwd("D:/competition kaggle/NBA_GAMES")
library(tidyverse)
library(caret) # this library will be used to split the data
setwd("D:/competition kaggle/NBA_GAMES")
library(tidyverse)
library(caret) # this library will be used to split the data
library(mlr3) # this library will be use to build a model
games<-read.csv("new_data/games_with_all_stat.csv")
test<- filter(games,games$GAME_DATE_EST>="2016-10-24")
train_data<- filter(games,games$GAME_DATE_EST<"2016-10-24")
view(train_data)
setwd("D:/competition kaggle/NBA_GAMES")
setwd("D:/competition kaggle/NBA_GAMES")
library(tidyverse)
library(plyr)
library(mice)
library(data.table)
Team<-as_tibble(read.csv("data/teams.csv"))
games<-as_tibble(read.csv("data/games.csv"))
nrow(games)
games$HOME_TEAM_ID<-as_factor(games$HOME_TEAM_ID)
games$TEAM_ID_away<-as_factor(games$TEAM_ID_away)
games$VISITOR_TEAM_ID<-as_factor(games$VISITOR_TEAM_ID)
games$TEAM_ID_home<-as_factor(games$TEAM_ID_home)
games$GAME_STATUS_TEXT<-as_factor(games$GAME_STATUS_TEXT)
games$GAME_DATE_EST<-as.Date(games$GAME_DATE_EST)
fact<-c()
for (i in 1:30){
l = as.numeric(levels(games$HOME_TEAM_ID)[i])
l = which(Team$TEAM_ID==l)
fact<-append(fact,Team$NICKNAME[l])
}
games$HOME_TEAM_ID <- mapvalues(games$HOME_TEAM_ID, from = levels(games$HOME_TEAM_ID), to=fact)
games$TEAM_ID_away <- mapvalues(games$TEAM_ID_away, from = levels(games$TEAM_ID_away), to=fact)
games$VISITOR_TEAM_ID <- mapvalues(games$VISITOR_TEAM_ID, from = levels(games$VISITOR_TEAM_ID), to=fact)
games$TEAM_ID_home <- mapvalues(games$TEAM_ID_home, from = levels(games$TEAM_ID_home), to=fact)
# count the number of duplicate number
sum(duplicated(games$GAME_ID))
#remove duplicated number
games<- games[!duplicated(games$GAME_ID),]
# Let's check whether we still have duplicate row
sum(duplicated(games$GAME_ID))
games<-select(games,-GAME_STATUS_TEXT,-TEAM_ID_home,-TEAM_ID_away,-PTS_away,
-FG_PCT_away,-FT_PCT_away,-FG3_PCT_away,-AST_away,-REB_away )
# number of missing values
sum(is.na(games$PTS_home))
setwd("D:/competition kaggle/NBA_GAMES")
library(tidyverse)
library(plyr)
library(mice)
library(data.table)
Team<-as_tibble(read.csv("data/teams.csv"))
games<-as_tibble(read.csv("data/games.csv"))
str(Team)
games$HOME_TEAM_ID<-as_factor(games$HOME_TEAM_ID)
games$TEAM_ID_away<-as_factor(games$TEAM_ID_away)
games$VISITOR_TEAM_ID<-as_factor(games$VISITOR_TEAM_ID)
games$TEAM_ID_home<-as_factor(games$TEAM_ID_home)
games$GAME_STATUS_TEXT<-as_factor(games$GAME_STATUS_TEXT)
games$GAME_DATE_EST<-as.Date(games$GAME_DATE_EST)
fact<-c()
for (i in 1:30){
l = as.numeric(levels(games$HOME_TEAM_ID)[i])
l = which(Team$TEAM_ID==l)
fact<-append(fact,Team$NICKNAME[l])
}
games$HOME_TEAM_ID <- mapvalues(games$HOME_TEAM_ID, from = levels(games$HOME_TEAM_ID), to=fact)
games$TEAM_ID_away <- mapvalues(games$TEAM_ID_away, from = levels(games$TEAM_ID_away), to=fact)
games$VISITOR_TEAM_ID <- mapvalues(games$VISITOR_TEAM_ID, from = levels(games$VISITOR_TEAM_ID), to=fact)
games$TEAM_ID_home <- mapvalues(games$TEAM_ID_home, from = levels(games$TEAM_ID_home), to=fact)
# count the number of duplicate games
sum(duplicated(games$GAME_ID))
#remove duplicated games
games<- games[!duplicated(games$GAME_ID),]
# Let's check whether we still have duplicate row
sum(duplicated(games$GAME_ID))
# Let's select important columns statistic for prediction, since all our games are unique, game_ID will be removed
view(games)
games<-select(games,-GAME_ID, -GAME_STATUS_TEXT,-TEAM_ID_home,-TEAM_ID_away )
view(games)
names(games)
# number of missing values
sum(is.na(games$PTS_home))
sum(is.na(games$FG_PCT_home))
sum(is.na(games$FT_PCT_home))
sum(is.na(games$FG3_PCT_home))
sum(is.na(games$REB_home))
sum(is.na(games$HOME_TEAM_WINS))
sum(is.na(games$PTS_away))
sum(is.na(games$FG_PCT_away))
sum(is.na(games$FT_PCT_away))
sum(is.na(games$FG3_PCT_home))
sum(is.na(games$AST_away))
sum(is.na(games$REB_away))
setwd("D:/competition kaggle/NBA_GAMES")
library(tidyverse)
library(caret) # this library will be used to split the data
library(mlr3) # this library will be use to build a model
games<-read.csv("new_data/games_with_all_stat.csv")
test<- filter(games,games$GAME_DATE_EST>="2016-10-24")
train_data<- filter(games,games$GAME_DATE_EST<"2016-10-24")
view(train_data)
# feature extraction,
names(train_data)
train_data<-select(train_data,-GAME_DATE_EST,-VISITOR_TEAM_ID, -SEASON,-HOME_TEAM_ID)
view(train_data)
set.seed(3456)
trainIndex <- createDataPartition(train_data$HOME_TEAM_WINS, p = .85,
list = FALSE,
times = 1)
Train <- train_data[ trainIndex,]
test_data <- train_data[-trainIndex,] # this data will be use to test the model
# let's visualize the distribution of data
sum(Train$HOME_TEAM_WINS==1)
sum(Train$HOME_TEAM_WINS==0)
sum(Train$HOME_TEAM_WINS==0)-sum(Train$HOME_TEAM_WINS==1)
#################Decision tree##############################
winner<- makeClassifTask(data=Train, target="HOME_TEAM_WINS")
tree <- makeLearner("classif.rpart")
getParamSet(tree)
setwd("D:/competition kaggle/NBA_GAMES")
library(tidyverse)
library(caret) # this library will be used to split the data
library(mlr) # this library will be use to build a model
test<- filter(games,games$GAME_DATE_EST>="2016-10-24")
#################Decision tree##############################
winner<- makeClassifTask(data=Train, target="HOME_TEAM_WINS")
tree <- makeLearner("classif.rpart")
getParamSet(tree)
setwd("D:/competition kaggle/NBA_GAMES")
library(tidyverse)
library(caret) # this library will be used to split the data
library(mlr)
games<-read.csv("new_data/games_with_all_stat.csv")
test<- filter(games,games$GAME_DATE_EST>="2016-10-24")
train_data<- filter(games,games$GAME_DATE_EST<"2016-10-24")
view(train_data)
# feature extraction,
names(train_data)
train_data<-select(train_data,-GAME_DATE_EST,-VISITOR_TEAM_ID, -SEASON,-HOME_TEAM_ID)
view(train_data)
set.seed(3456)
trainIndex <- createDataPartition(train_data$HOME_TEAM_WINS, p = .85,
list = FALSE,
times = 1)
Train <- train_data[ trainIndex,]
test_data <- train_data[-trainIndex,] # this data will be use to test the model
# let's visualize the distribution of data
sum(Train$HOME_TEAM_WINS==1)
sum(Train$HOME_TEAM_WINS==0)
sum(Train$HOME_TEAM_WINS==0)-sum(Train$HOME_TEAM_WINS==1)
winner<- makeClassifTask(data=Train, target="HOME_TEAM_WINS")
logreg<-makeLearner("classif.logreg")
logregModel<-train(logreg,winner)
print(logregModel)
# cross-validating our logistic regression model
logRegWrapper<-makeImputeWrapper("classif.logreg")
Kfold <-makeResampleDesc(method = "RepCV",folds=5,reps=50,stratify = TRUE)
Kfold
logRegwithImpute<-resample(logRegWrapper,winner,resampling = Kfold, measures = list(acc, fpr, fnr))
logRegwithImpute
logRegModelData<-getLearnerModel(logregModel)
coef(logRegModelData)
# feature extraction,
names(train_data)
train_data<-select(train_data,-GAME_DATE_EST,-VISITOR_TEAM_ID, -SEASON,-HOME_TEAM_ID)
view(train_data)
set.seed(3456)
trainIndex <- createDataPartition(train_data$HOME_TEAM_WINS, p = .85,
list = FALSE,
times = 1)
Train <- train_data[ trainIndex,]
test_data <- train_data[-trainIndex,] # this data will be use to test the model
# let's visualize the distribution of data
sum(Train$HOME_TEAM_WINS==1)
sum(Train$HOME_TEAM_WINS==0)
sum(Train$HOME_TEAM_WINS==0)-sum(Train$HOME_TEAM_WINS==1)
winner<- makeClassifTask(data=Train, target="HOME_TEAM_WINS")
logreg<-makeLearner("classif.logreg")
logregModel<-train(logreg,winner)
print(logregModel)
# cross-validating our logistic regression model
logRegWrapper<-makeImputeWrapper("classif.logreg")
Kfold <-makeResampleDesc(method = "RepCV",folds=5,reps=50,stratify = TRUE)
Kfold
logRegwithImpute<-resample(logRegWrapper,winner,resampling = Kfold, measures = list(acc, fpr, fnr))
logRegwithImpute
predicted<-predict(logregModel, newdata = test_data,type="class")
truth<-predicted$data$truth
response<-predicted$data$response
length(which(truth!=response))/length(predicted$data)
#Creating confusion matrix   https://www.journaldev.com/46732/confusion-matrix-in-r
example <- confusionMatrix(data=as_factor(response), reference = as_factor(truth))
#Display results
example
install.packages("Boruta")
install.packages("mlbench")
library(mlbench)
library(Boruta)
library(mlbench)
library(randomForest)
boruto<-Boruta(HOME_TEAM_WINS~.,data = Train,doTrace=2)
view(Train)
boruto<-Boruta(HOME_TEAM_WINS~.,data = Train,doTrace=2, maxRuns=100)
print(boruto)
plot(boruto)
plot(boruto,las=2)
view(Train)
plot(boruto,las=2,cex.axis=0.7)
plotImpHistory(boruto)
bor<-TentativeRoughFix(boruto)
bor
getNonRejectedFormula(boruta)
getNonRejectedFormula(boruto)
tet<-select(Train,PTS_home,PTS_away,FG_PCT_home,FT_PCT_away )
mdl<- makeClassifTask(data=Train, target="HOME_TEAM_WINS")
logreg<-makeLearner("classif.logreg")
logregModel<-train(logreg,mdl)
tet<-select(Train,PTS_home,PTS_away,FG_PCT_home,FT_PCT_away,HOME_TEAM_WINS )
mdl<- makeClassifTask(data=tet, target="HOME_TEAM_WINS")
logreg<-makeLearner("classif.logreg")
logregModel<-train(logreg,mdl)
testt<-select(test_data,)
testt<-select(test_data,PTS_home,PTS_away,FG_PCT_home,FT_PCT_away,HOME_TEAM_WINS)
predicted<-predict(logregModel, newdata = testt,type="class")
truth<-predicted$data$truth
response<-predicted$data$response
length(which(truth!=response))/length(predicted$data)
#Creating confusion matrix   https://www.journaldev.com/46732/confusion-matrix-in-r
example <- confusionMatrix(data=as_factor(response), reference = as_factor(truth))
#Display results
example
view(tet)
mdl<- makeClassifTask(data=tet, target="HOME_TEAM_WINS")
lr<-makeLearner("classif.logreg")
logr<-train(lr,mdl)
testt<-select(test_data,PTS_home,PTS_away,FG_PCT_home,FT_PCT_away,HOME_TEAM_WINS)
predicted<-predict(logr, newdata = testt,type="class")
truth<-predicted$data$truth
response<-predicted$data$response
length(which(truth!=response))/length(predicted$data)
#Creating confusion matrix   https://www.journaldev.com/46732/confusion-matrix-in-r
example <- confusionMatrix(data=as_factor(response), reference = as_factor(truth))
#Display results
example
setwd("D:/competition kaggle/NBA_GAMES")
library(tidyverse)
library(caret) # this library will be used to split the data
library(mlr)
games<-read.csv("new_data/games_with_all_stat.csv")
test<- filter(games,games$GAME_DATE_EST>="2016-10-24")
train_data<- filter(games,games$GAME_DATE_EST<"2016-10-24")
view(train_data)
# feature extraction,
names(train_data)
train_data<-select(train_data,-GAME_DATE_EST,-VISITOR_TEAM_ID, -SEASON,-HOME_TEAM_ID)
view(train_data)
set.seed(3456)
trainIndex <- createDataPartition(train_data$HOME_TEAM_WINS, p = .85,
list = FALSE,
times = 1)
Train <- train_data[ trainIndex,]
test_data <- train_data[-trainIndex,] # this data will be use to test the model
# let's visualize the distribution of data
sum(Train$HOME_TEAM_WINS==1)
sum(Train$HOME_TEAM_WINS==0)
sum(Train$HOME_TEAM_WINS==0)-sum(Train$HOME_TEAM_WINS==1)
winner<- makeClassifTask(data=Train, target="HOME_TEAM_WINS")
logreg<-makeLearner("classif.logreg")
logregModel<-train(logreg,winner)
print(logregModel)
# cross-validating our logistic regression model
logRegWrapper<-makeImputeWrapper("classif.logreg")
Kfold <-makeResampleDesc(method = "RepCV",folds=5,reps=50,stratify = TRUE)
Kfold
logRegwithImpute<-resample(logRegWrapper,winner,resampling = Kfold, measures = list(acc, fpr, fnr))
logRegwithImpute
logRegModelData<-getLearnerModel(logregModel)
coef(logRegModelData)
predicted<-predict(logregModel, newdata = test_data,type="class")
truth<-predicted$data$truth
response<-predicted$data$response
length(which(truth!=response))/length(predicted$data)
#Creating confusion matrix   https://www.journaldev.com/46732/confusion-matrix-in-r
example <- confusionMatrix(data=as_factor(response), reference = as_factor(truth))
#Display results
example
library(Boruta)
library(mlbench)
library(randomForest)
set.seed(111)
tet<-select(Train,PTS_home,PTS_away,FG_PCT_home,FT_PCT_away,HOME_TEAM_WINS )
mdl<- makeClassifTask(data=tet, target="HOME_TEAM_WINS")
lr<-makeLearner("classif.logreg")
logr<-train(lr,mdl)
testt<-select(test_data,PTS_home,PTS_away,FG_PCT_home,FT_PCT_away,HOME_TEAM_WINS)
predicted<-predict(logr, newdata = testt,type="class")
truth<-predictedt$data$truth
predictedt<-predict(logr, newdata = testt,type="class")
truth<-predictedt$data$truth
responset<-predictedt$data$response
length(which(trutht!=responset))/length(predictedt$data)
trutht<-predictedt$data$truth
responset<-predictedt$data$response
length(which(truth!=responset))/length(predictedt$data)
#Creating confusion matrix   https://www.journaldev.com/46732/confusion-matrix-in-r
example <- confusionMatrix(data=as_factor(responset), reference = as_factor(trutht))
#Creating confusion matrix   https://www.journaldev.com/46732/confusion-matrix-in-r
examplet <- confusionMatrix(data=as_factor(responset), reference = as_factor(trutht))
#Display results
examplet
# cross-validating our logistic regression model
logRWrapper<-makeImputeWrapper("classif.logreg")
Kfoldt <-makeResampleDesc(method = "RepCV",folds=5,reps=50,stratify = TRUE)
Kfoldt
logRwithImpute<-resample(logRWrapper,mdl,resampling = Kfoldt, measures = list(acc, fpr, fnr))
logRwithImpute
